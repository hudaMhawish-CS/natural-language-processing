{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# جمع ملفات التدريب والاختبار ووضعها في ملف واحد للاختبار وملف واحد للتدريب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# جمع ملفات التدريب في ملف واحد\n",
    "file = open(\"train.txt\", \"w\",encoding='utf-8')\n",
    "for i in os.listdir(\"file/\"):\n",
    "    if i.endswith('.txt'):\n",
    "        f=\"file/\"+i\n",
    "        fi = open(f, \"r\",encoding='utf-8')\n",
    "        string=fi.read()\n",
    "        file.write(string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# جمع ملفات الاختبار في ملف واحد\n",
    "file_test = open(\"test.txt\", \"w\",encoding='utf-8')\n",
    "for i in os.listdir(\"test/\"):\n",
    "    if i.endswith('.txt'):\n",
    "        f=\"test/\"+i\n",
    "        fi = open(f, \"r\",encoding='utf-8')\n",
    "        string=fi.read()\n",
    "        file_test.write(string)\n",
    "file_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv عدد التغريدات كبير ما فيني عدل يدويا بسبب هالشي رح عدل التغريدات ليزبط شكلن قبل ما يتخزنو بملف\n",
    "pos|neg لتتوحد كل تاغات التغريدات وحدت شكل\n",
    "اخدت التغريدات فقط التي بتحوي على تاغ\n",
    "neg و pos حذفت الروابط لان في طلاب حاطين || قبلها وعم يروح الرابط كتاغ بدون\n",
    " tag بالنهاية ضلت التغريدات بدون روابط ومع"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv عدد التغريدات كبير ما فيني عدل يدويا بسبب هالشي رح عدل التغريدات ليزبط شكلن قبل ما يتخزنو بملف \n",
    "pattern=r'pos|neg'\n",
    "file= open(\"train.txt\", \"r\",encoding='utf-8')\n",
    "file_1= open(\"train_1.txt\", \"w\",encoding='utf-8')\n",
    "for i in file.readlines():\n",
    "    out =i.lower()     #  pos و neg  لتتوحد كل تاغات التغريدات وحدت شكل\n",
    "    if re.search(pattern,out): # اخدت التغريدات فقط التي بتحوي على تاغ\n",
    "        pattern_1=r'(http\\S+)|((\\w(\\d)?)+(.(\\w(\\d)?)+)?.com\\S+)|(www\\.[\\s]+)' \n",
    "        out=re.sub(pattern_1,' ',out) #neg و pos حذفت الروابط لان في طلاب حاطين || قبلها وعم يروح الرابط كتاغ بدون\n",
    "        file_1.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()\n",
    "file_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=r'pos|neg'\n",
    "file= open(\"test.txt\", \"r\",encoding='utf-8')\n",
    "file_1= open(\"test_1.txt\", \"w\",encoding='utf-8')\n",
    "for i in file.readlines():\n",
    "    out =i.lower()     #  pos و neg  لتتوحد كل تاغات التغريدات وحدت شكل\n",
    "    if re.search(pattern,out): # اخدت التغريدات فقط التي بتحوي على تاغ\n",
    "        pattern_1=r'(http\\S+)|((\\w(\\d)?)+(.(\\w(\\d)?)+)?.com\\S+)|(www\\.[\\s]+)' \n",
    "        out=re.sub(pattern_1,' ',out) #neg و pos حذفت الروابط لان في طلاب حاطين || قبلها وعم يروح الرابط كتاغ بدون\n",
    "        file_1.write(out)\n",
    "file.close()\n",
    "file_1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.csv تخزين التغريدات للتدريب في ملف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.csv تخزين التغريدات للتدريب في ملف\n",
    "file_2= open(\"train_1.txt\", \"r\",encoding='utf-8')\n",
    "file_3= open(\"train.csv\", \"w\",encoding='utf-8-sig')\n",
    "fieldnames = ['tweet', 'tag']\n",
    "writer = csv.DictWriter(file_3, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for i in file_2.readlines():\n",
    "    i = i.replace(',', ' ')\n",
    "    i = i.replace('||', ',')\n",
    "    file_3.write(i)\n",
    "file_2.close()\n",
    "file_3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test.csv تخزين التغريدات للاختبار في ملف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.csv تخزين التغريدات للاختبار في ملف\n",
    "file_2= open(\"test_1.txt\", \"r\",encoding='utf-8')\n",
    "file_3= open(\"test.csv\", \"w\",encoding='utf-8-sig')\n",
    "fieldnames = ['tweet', 'tag']\n",
    "writer = csv.DictWriter(file_3, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for i in file_2.readlines():\n",
    "    i = i.replace(',', ' ')\n",
    "    i = i.replace('||', ',')\n",
    "    file_3.write(i)\n",
    "file_2.close()\n",
    "file_3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "قراءة التغريدات وتخزينها في متحول"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# قراءة التغريدات وتخزينها في متحول\n",
    "import pandas as pd\n",
    "tweets=pd.read_csv('train.csv',error_bad_lines=False,names=[\"tweet\",\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test=pd.read_csv('test.csv',error_bad_lines=False,names=[\"tweet\",\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of tuple تحويل التغريدات ل \n",
    "data_t = [tuple(x) for x in tweets.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ts = [tuple(x) for x in tweets_test.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[tuple(i) for i in data_t if i[1]==\"neg\" or i[1]==\"pos\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[tuple(i) for i in data_ts if i[1]==\"neg\" or i[1]==\"pos\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081\n",
      "4727\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train))\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('تحتاج الولاية الى تقنين حسب مقتضى الحال في الوكالة النظر الى عمر المرأة وسلوكها وتقنينها من ناحيه حق المرأة في إدارة اموالها وفِي حقها في مايخص ابنائها من ناحيه الحضانه واعطائها حق الولايه في حالات الطلاق وموت الزوج اذا هي مؤهله وهكذ #الشعب_يرفض_اسقاط_الولايه',\n",
       "  'neg'),\n",
       " ('#الشعب_يرفض_اسقاط_الولايه اعرف من تبنى فكرة تاق اسقاط الولايه : مجنسين ابناء زوجه غير سعوديه ابناء متخلفي الحج والعمره من يعاني من مشاكل اجتماعيه من احداث السن والسفهاء الذين يسهل التغرير بهم...الخ حينها تعرف ان الموضوع يخص مجتمعات اخرى غير المجتمع السعودي ',\n",
       "  'neg'),\n",
       " ('#الشعب_يرفض_اسقاط_الولايه سبحان الله الحمدالله لا إله الا الله الله أكبر سبحان الله وبحمده سبحان الله العظيم استغفرالله وأتوب إليه لا إله الا انت سبحانك اني كنت من الظالمين اللهم صل وسلم على نبينا محمد',\n",
       "  'neg'),\n",
       " ('أطالب بإلغاء هذا الهاشتاق وعدم الالتفات الى مثل هذة الهاشتاقات التافهة ومن يديرها ليسوا سعوديين بل مرتزقة حمقى لايفقهون شيءً ومعظمهم لدية شهادة سادس ابتدائي أو ثالث متوسط ولَم ينهوا تعليمهم ،الشعب السعودي واعي وفاهم وأصيل لايهتم بمثل هذة الأمور . #الشعب_يرفض_اسقاط_الولايه',\n",
       "  'neg'),\n",
       " ('#الشعب_يرفض_اسقاط_الولايه الله يخلي لنا رجالنا ويطول في اعمارهم بدونهم حياتنا ما تكمل والله لمن يشد علي امر ارجع اتكلم مع اخوي لانه سندي والاب ما يتعوض ولا يحس بالفقد الا الي فقد ابوه الله يرحم ابوي ويطول بعمر امي واخواني والله يرزقني بزوج صالح ويخاف الله فيني',\n",
       "  'neg'),\n",
       " ('#سعوديات_نفخر_بولايه_اهلنا_لنا #الشعب_يرفض_اسقاط_الولايه لابد من اظهار ورفع كلمة #الشعب_السعودي الحقيقي إلى الأعلى والأعلى، ولن يمثلنا ظال أو غيره من ذوي الافكار الغير سوية. الحمد لله حمدا طيبا كثيرا مباركاً فيه حتى يبلغ الحمد منهاه',\n",
       "  'neg'),\n",
       " ('الولاية حفظ للمرأة وحماية لها من شرور هذي الحياة بغض النظر عن من يستغلها في غير محلها ونحن لا نتبع الغرب بل نتبع دين الله ومنهج نبيه محمد صلى الله عليه وسلم ومن اتبع غيره فلن يفلح ابداً،،، وحسبنا الله ونعم الوكيل على مطايا العلمانية . #الشعب_يرفض_اسقاط_الولايه',\n",
       "  'neg'),\n",
       " ('أحس بسعادة كل ما أشوفه ترند #سعوديات_نطلب_اسقاط_الولايه', 'pos'),\n",
       " ('حفظ المراءة هو حفظ وأمان للمجتمع ..يعني اللي تطالب بإسقاط الولاية داشره من الآخر',\n",
       "  'neg'),\n",
       " ('#الشعب_يرفض_اسقاط_الولايه وش كلام الفاضي هذا اسقاط الولايه ليه تصير البنت تروح وتجي محد يحكمها بأي مذهب هذا كل رجال سعودي طبعه غيور ولا يرضى اذل عل نفسه أو على غيره وشكل العقال بشتغل هل يومين مير احمدو الله عل النعمه وستر والحمد الله الدوله ما تقصر اي احد أخطأ باحد',\n",
       "  'neg')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('وصف مطابق للطابور الخامس الذي يزعزع أمننا..! #إسقاط_العباية #اسقاط_الولاية #سعوديون_نرفض_دمج_المدارس  …',\n",
       "  'neg'),\n",
       " ('ألقوه ألقوه لابارك الله بالضعف سكتنا عن القرارات الهمجيه حقتكم من إسقاط الولايه الى قياده المراه الى توظيف النساء ف المحلات الان ع كل أولياء الأمور التجمع امام المدرسه والاعتراض غير كذا مايفيد معهم شي نبغى تطبيق شرع الله لاأقل ولا اكثر #سعوديون_نرفض_دمج_المدارس',\n",
       "  'neg'),\n",
       " ('ألقوه ألقوه لابارك الله بالضعف سمتنا عن القرارات الهمجيه حقتكم من إسقاط الولايه الو قياده المراه الى توظيف النساء ف المحلات الان ع كل أولياء الأمور التجمع انام المدرسه والاعتراض غير كذا مايفيد معهم شي #سعوديون_نرفض_دمج_المدارس',\n",
       "  'neg'),\n",
       " ('#سعوديون_نرفض_دمج_المدارس 1-الغاء هيئة الامر بالمعروف والنهي عن المنكر 2-هيئه الترفيه 3- الحفلات والرقص 4-ازدياد التبرج 5-الاختلاط بالوظائف 6- الضرائب 7-السماح للنساء بقيادة السيارة 8-اسقاط الولاية 9-دمج التعليم 10- 11- 12- 13 14- 15',\n",
       "  'neg'),\n",
       " ('#سعوديون_نرفض_دمج_المدا رس لن ينتهي الامر عن هذا الحد ولا هذا القرار .. كل يوم قرار جديد في تغريب المجتمع وإخراج الناس من الدين ونشر اسباب الرذيلة والفواحش وتفكك الاسرة !! والمصيبة عندما تم اقرار اسقاط الولاية واعترض البعض، قالوا؛ ربوا بناتكم! كيف أربي وانت قاعد تفسد كل شي',\n",
       "  'neg'),\n",
       " ('#سعوديات_نطلب_اسقاط_القبيله.. نعم نحنا سعوديات بنات قبائل.. نعم نحنا سعوديات ونرفض بقوه اي قرار في إسقاط الولايه والقبيله هي مرجع لكل إنسان.. حر.. من أرض حره. نعم وبقوة نرفض الفساد الذي يمس حكم الله وديننا نعم سعوديات احرار بنات رجال ونساء وأرض حره',\n",
       "  'neg'),\n",
       " ('شرع الله لايبدل مثلما رفضنا إسقاط الولاية عن المرأة لانها من صميم الدين نحن نرفض إسقاط المهر والنفقه لانها واجبه على الرجل #اسقاط_النفقه_المهر_عن_السعودي1',\n",
       "  'neg'),\n",
       " ('#سعوديات_نطلب_اسقاط_الولايه1116. سعوديات نعم سعوديات نرفض وبقوه اي قرار فيه مفسده للاسره ونرفض قرار إسقاط الولايه ونرفض الاختلاط ونطالب بشده إلغاء هئية الترفيه وإنما هي هيئه الفساد للناس ونرفض كل كل مايمس الدين والادعاء بحرية المرأة تحت مسمى حقوق المرأة',\n",
       "  'neg'),\n",
       " ('#سعوديات_نطلب_اسقاط_الولايه1116 حسبي الله عليكم الحين الكل عباله اننا مسجونات والله عايشات احسن عيشه نحن السعوديات اصل وفصل ما طالبنا بذا الشيء ابد المفروض كل ما يسوون هشتاق اسقاط الولايه نسوي مثله نرفض اسقاطها عيب وربي عيب صرتم مضحكه للكل',\n",
       "  'neg'),\n",
       " ('ليش عندكم الولايه بس لسفر!! اكيد البنت اللي حاشمه ولي امرها ماراح تسافر إلا برضاه لكن انتي عندك خبر عن اللي بالسجن ياتطلع بموافقة وليها ولا تجلس بدار الرعايه لحد ماتموت وغيره وغيره، ومو معناته ربي رزقنا بأهل متفهين مانراعي ظروف غيرنا ولا بكل انانيه نرفض اسقاط الولايه وكأنها كفر',\n",
       "  'neg')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Text Cleaning and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# حذف التغريدات المكررة\n",
    "def del_freq (data) : \n",
    "    data_1=[t for t in (set(tuple(i) for i in data))]\n",
    "    return data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Text Cleaning and Normalization\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('arabic'))\n",
    "def clean_stop_norm(text):\n",
    "    pattern=r'@|;|؛|،|ٍٍ/|\\(|\\)|{|}|\\[|\\]|\\|'\n",
    "    t=re.sub(pattern,' ',str(text)) #استبدال محارف محددة\n",
    "    pattern_d=r'(..)\\1+'\n",
    "    t = re.sub(pattern_d, r'\\1', str(t))\n",
    "    symbol=[\"ئ\",\"ة\",\"أ\",\"إ\",\"آ\",\"ؤ\"] \n",
    "    sumb_1=[\"ء\",\"ه\",\"ا\",\"ا\",\"ا\",\"ء\"]\n",
    "    for i in range(6):\n",
    "        t = str(t).replace(symbol[i], sumb_1[i])\n",
    "    t = nltk.sent_tokenize(t)\n",
    "    t =[w for w in t if not w in STOPWORDS]\n",
    "    t = \" \".join(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1=del_freq (data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=del_freq (data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7067\n",
      "4258\n"
     ]
    }
   ],
   "source": [
    "# عدد التغريدات بعد ازالة التكرار\n",
    "print(len(data_1))\n",
    "print(len(data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_t=[(clean_stop_norm(i[0]),i[1])for i in data_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_t=[(clean_stop_norm(i[0]),i[1])for i in data_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# فصل البيانات الى اختبار وتدريب\n",
    "X_train = [example[0] for example in data_train_t]\n",
    "y_train = [example[1] for example in data_train_t]\n",
    "\n",
    "X_test = [example[0] for example in data_test_t]\n",
    "y_test = [example[1] for example in data_test_t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return Bag of words vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create Count vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test, and val sets and return the result\n",
    "    \n",
    "    count_vectorizer = CountVectorizer(ngram_range=(1, 2)) \n",
    "    X_train_Vec = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_Vec = count_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train_Vec, X_test_Vec, count_vectorizer.vocabulary_ ,count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bag, X_test_bag, bow_vocab,count_vectorizer_bag = bow_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test, and val sets and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.7, ngram_range=(1, 2))\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, tfidf_vectorizer.vocabulary_,tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, tfidf_vocab ,tfidf_vectorizer_tf= tfidf_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "def train_classifier(X_train, y_train):\n",
    "    classifier = RidgeClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bag = train_classifier(X_train_bag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_labels_bag = classifier_bag.predict(X_test_bag)\n",
    "y_test_predicted_scores_bag = classifier_bag.decision_function(X_test_bag)\n",
    "\n",
    "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "y_test_predicted_scores_tfidf = classifier_tfidf.decision_function(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:\tاغلب النساء لم يكن الرادع لهن من السفر بدون محرم قوانين حكوميه! بل كان الرادع الرءيسي لديهن طاعه الل...\n",
      "True Tag:\tneg\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n",
      "Tweet:\t#السعوديه ... قريبا ستذهب نساءنا للحج بدون ذي محرم كما تراجعوا عن اخذ جواز سفر المراه من دون اذن ولي...\n",
      "True Tag:\tneg\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n",
      "Tweet:\tالحملات المغرضه تتغاضى عن النماذج المتميزه لغالبيهالاباء والازواج والاخوهالذين يرعون ويهتمون بامهاته...\n",
      "True Tag:\tneg\n",
      "Predicted label BoW:\tpos\n",
      "Predicted label Tf_Idf:\tpos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('Tweet:\\t{}\\nTrue Tag:\\t{}\\nPredicted label BoW:\\t{}\\nPredicted label Tf_Idf:\\t{}\\n\\n'.format(\n",
    "        X_test[i][:100] + \"...\",y_test[i],y_test_predicted_labels_bag[i], y_test_predicted_labels_tfidf[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words Accuracy: 0.7909816815406294\n",
      "Tfidf Accuracy: 0.8048379520901832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Bag-of-words Accuracy: '+ str(accuracy_score(y_test, y_test_predicted_labels_bag)))\n",
    "print('Tfidf Accuracy: ' + str(accuracy_score(y_test, y_test_predicted_labels_tfidf)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "وصلتلو Accuracy اعلا \n",
    "بتعديل min ,max\n",
    "Bag-of-words Accuracy: 0.791451385627055\n",
    "Tfidf Accuracy: 0.8046031000469704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-لتصنيف تغريدة يقوم المستخدم بإدخالها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter tweet رفع الولاية\n",
      "['pos']\n",
      "['pos']\n"
     ]
    }
   ],
   "source": [
    "# 3-لتصنيف تغريدة يقوم المستخدم بإدخالها\n",
    "tweet=input(\"enter tweet \")\n",
    "\n",
    "print(classifier_bag.predict(count_vectorizer_bag.transform([tweet])[0]))\n",
    "print(classifier_tfidf.predict(tfidf_vectorizer_tf.transform([tweet])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-stemmingالتصنيف بعد القيام بعمليات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-stemmingالتصنيف بعد القيام بعمليات   \n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "def stem_text(in_text):\n",
    "    out_text = \" \".join(porter.stem(w) for w in in_text.split())\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_stem=[(stem_text(i[0]),i[1])for i in data_train_t]\n",
    "data_test_stem=[(stem_text(i[0]),i[1])for i in data_test_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [example[0] for example in data_train_stem]\n",
    "y_train = [example[1] for example in data_train_stem]\n",
    "\n",
    "X_test = [example[0] for example in data_test_stem]\n",
    "y_test = [example[1] for example in data_test_stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bag, X_test_bag, bow_vocab = bow_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bag = train_classifier(X_train_bag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_labels_bag = classifier_bag.predict(X_test_bag)\n",
    "y_test_predicted_scores_bag = classifier_bag.decision_function(X_test_bag)\n",
    "\n",
    "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "y_test_predicted_scores_tfidf = classifier_tfidf.decision_function(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:\tسعوديات نطلب اسقاط الولايه1000 هذا التاق بدون قاءده تغرد فيه كل امراه سعوديه حتى لو لم يتجاوز متابعي...\n",
      "True Tag:\tpos\n",
      "Predicted label BoW:\tpos\n",
      "Predicted label Tf_Idf:\tpos\n",
      "\n",
      "\n",
      "Tweet:\tالشعب يرفض اسقاط الولايه قال صلى الله عليه وسلم\"كُلُّكُمْ رَاعٍ وَكُلُّكُمْ مَسْءول عَنْ رَعِيَّتِهِ...\n",
      "True Tag:\tneg\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n",
      "Tweet:\tاسقاط الولايه بعد الـ 18 قد يسقط حق الميراث لمن تسقط ولايته والزواج سيعيد الفتاه لولايه الزوج قرار ا...\n",
      "True Tag:\tpos\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('Tweet:\\t{}\\nTrue Tag:\\t{}\\nPredicted label BoW:\\t{}\\nPredicted label Tf_Idf:\\t{}\\n\\n'.format(\n",
    "        X_test[i][:100] + \"...\",y_test[i],y_test_predicted_labels_bag[i], y_test_predicted_labels_tfidf[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words Accuracy: 0.7912165335838421\n",
      "Tfidf Accuracy: 0.8046031000469704\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words Accuracy: '+ str(accuracy_score(y_test, y_test_predicted_labels_bag)))\n",
    "print('Tfidf Accuracy: ' + str(accuracy_score(y_test, y_test_predicted_labels_tfidf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ما اثر steeming على التدريب\n",
    "Bag-of-words Accuracy: 0.7912165335838421\n",
    "Tfidf Accuracy: 0.8046031000469704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- التصنيف بعد حذف الهاشتاغ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- التصنيف بعد حذف الهاشتاغ\n",
    "pattern=r'#(\\S+_\\S+)+'\n",
    "\n",
    "def del_hash_tag(text):\n",
    "    out=re.sub(pattern,' ',text)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_has=[(del_hash_tag(i[0]),i[1])for i in data_train_t]\n",
    "data_test_has=[(del_hash_tag(i[0]),i[1])for i in data_test_t]\n",
    "\n",
    "X_train = [example[0] for example in data_train_has]\n",
    "y_train = [example[1] for example in data_train_has]\n",
    "\n",
    "X_test = [example[0] for example in data_test_has]\n",
    "y_test = [example[1] for example in data_test_has]\n",
    "\n",
    "X_train_bag, X_test_bag, bow_vocab = bow_features(X_train, X_test)\n",
    "X_train_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_test)\n",
    "classifier_bag = train_classifier(X_train_bag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)\n",
    "y_test_predicted_labels_bag = classifier_bag.predict(X_test_bag)\n",
    "y_test_predicted_scores_bag = classifier_bag.decision_function(X_test_bag)\n",
    "\n",
    "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "y_test_predicted_scores_tfidf = classifier_tfidf.decision_function(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:\tسعوديات نطلب اسقاط الولايه1000 هذا التاق بدون قاءده تغرد فيه كل امراه سعوديه حتى لو لم يتجاوز متابعي...\n",
      "True Tag:\tpos\n",
      "Predicted label BoW:\tpos\n",
      "Predicted label Tf_Idf:\tpos\n",
      "\n",
      "\n",
      "Tweet:\tالشعب يرفض اسقاط الولايه قال صلى الله عليه وسلم\"كُلُّكُمْ رَاعٍ وَكُلُّكُمْ مَسْءول عَنْ رَعِيَّتِهِ...\n",
      "True Tag:\tneg\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n",
      "Tweet:\tاسقاط الولايه بعد الـ 18 قد يسقط حق الميراث لمن تسقط ولايته والزواج سيعيد الفتاه لولايه الزوج قرار ا...\n",
      "True Tag:\tpos\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('Tweet:\\t{}\\nTrue Tag:\\t{}\\nPredicted label BoW:\\t{}\\nPredicted label Tf_Idf:\\t{}\\n\\n'.format(\n",
    "        X_test[i][:100] + \"...\",y_test[i],y_test_predicted_labels_bag[i], y_test_predicted_labels_tfidf[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words Accuracy: 0.7806481916392672\n",
      "Tfidf Accuracy: 0.7881634570220761\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words Accuracy: '+ str(accuracy_score(y_test, y_test_predicted_labels_bag)))\n",
    "print('Tfidf Accuracy: ' + str(accuracy_score(y_test, y_test_predicted_labels_tfidf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " انخفضت بعد حذف الهاشتاغ\n",
    "Bag-of-words Accuracy: 0.7806481916392672\n",
    "Tfidf Accuracy: 0.7881634570220761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-  التصنيف بعد تحويل الهاشتاغات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-  التصنيف بعد تحويل الهاشتاغات\n",
    "\n",
    "def hash_tag(text):\n",
    "    out=re.sub('#','',text)\n",
    "    out=re.sub('_',' ',out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_has1=[(hash_tag(i[0]),i[1])for i in data_train_t]\n",
    "data_test_has1=[(hash_tag(i[0]),i[1])for i in data_test_t]\n",
    "\n",
    "X_train = [example[0] for example in data_train_has1]\n",
    "y_train = [example[1] for example in data_train_has1]\n",
    "\n",
    "X_test = [example[0] for example in data_test_has1]\n",
    "y_test = [example[1] for example in data_test_has1]\n",
    "\n",
    "X_train_bag, X_test_bag, bow_vocab = bow_features(X_train, X_test)\n",
    "X_train_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_test)\n",
    "classifier_bag = train_classifier(X_train_bag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)\n",
    "y_test_predicted_labels_bag = classifier_bag.predict(X_test_bag)\n",
    "y_test_predicted_scores_bag = classifier_bag.decision_function(X_test_bag)\n",
    "\n",
    "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "y_test_predicted_scores_tfidf = classifier_tfidf.decision_function(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:\tسعوديات نطلب اسقاط الولايه1000 هذا التاق بدون قاءده تغرد فيه كل امراه سعوديه حتى لو لم يتجاوز متابعي...\n",
      "True Tag:\tpos\n",
      "Predicted label BoW:\tpos\n",
      "Predicted label Tf_Idf:\tpos\n",
      "\n",
      "\n",
      "Tweet:\tالشعب يرفض اسقاط الولايه قال صلى الله عليه وسلم\"كُلُّكُمْ رَاعٍ وَكُلُّكُمْ مَسْءول عَنْ رَعِيَّتِهِ...\n",
      "True Tag:\tneg\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n",
      "Tweet:\tاسقاط الولايه بعد الـ 18 قد يسقط حق الميراث لمن تسقط ولايته والزواج سيعيد الفتاه لولايه الزوج قرار ا...\n",
      "True Tag:\tpos\n",
      "Predicted label BoW:\tneg\n",
      "Predicted label Tf_Idf:\tneg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('Tweet:\\t{}\\nTrue Tag:\\t{}\\nPredicted label BoW:\\t{}\\nPredicted label Tf_Idf:\\t{}\\n\\n'.format(\n",
    "        X_test[i][:100] + \"...\",y_test[i],y_test_predicted_labels_bag[i], y_test_predicted_labels_tfidf[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words Accuracy: 0.8062470643494598\n",
      "Tfidf Accuracy: 0.8163457022076092\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words Accuracy: '+ str(accuracy_score(y_test, y_test_predicted_labels_bag)))\n",
    "print('Tfidf Accuracy: ' + str(accuracy_score(y_test, y_test_predicted_labels_tfidf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ارتفعت بعد فصل الهاشتاغ\n",
    " Bag-of-words Accuracy: 0.8062470643494598\n",
    " Tfidf Accuracy: 0.8163457022076092"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
